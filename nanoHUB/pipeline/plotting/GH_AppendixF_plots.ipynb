{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build researcher events, student events, and self-study events\n",
    "## researcher are simply those with NH citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,928| WARNING | Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,928 - [WARNING] sshtunnel.SSHTunnelForwarder [sshtunnel._read_ssh_config:1032]: Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,934| INFO    | 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,934 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_agent_keys:1060]: 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,941| INFO    | 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,941 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_keys:1117]: 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,947| INFO    | Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:04,947 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.__init__:978]: Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n",
      "2021-07-22 17:30:04,957 - [\u001b[1mINFO\u001b[0m] \u001b[1mnanoHUB.containers.dataaccess\u001b[0m [connection.get_connection_for:78]: Started SSH Tunnel with db2.nanohub.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,164| INFO    | Opening tunnel: 0.0.0.0:37369 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,164 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel._serve_forever_wrapper:1433]: Opening tunnel: 0.0.0.0:37369 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,270| WARNING | Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,270 - [WARNING] sshtunnel.SSHTunnelForwarder [sshtunnel._read_ssh_config:1032]: Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,276| INFO    | 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,276 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_agent_keys:1060]: 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,286| INFO    | 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,286 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_keys:1117]: 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,292| INFO    | Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,292 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.__init__:978]: Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n",
      "2021-07-22 17:30:05,302 - [\u001b[1mINFO\u001b[0m] \u001b[1mnanoHUB.containers.dataaccess\u001b[0m [connection.get_connection_for:78]: Started SSH Tunnel with db2.nanohub.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,508| INFO    | Opening tunnel: 0.0.0.0:40021 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,508 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel._serve_forever_wrapper:1433]: Opening tunnel: 0.0.0.0:40021 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,610| WARNING | Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,610 - [WARNING] sshtunnel.SSHTunnelForwarder [sshtunnel._read_ssh_config:1032]: Could not read SSH configuration file: ~/.ssh/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,621| INFO    | 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,621 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_agent_keys:1060]: 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,630| INFO    | 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,630 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_keys:1117]: 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,637| INFO    | Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,637 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.__init__:978]: Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n",
      "2021-07-22 17:30:05,646 - [\u001b[1mINFO\u001b[0m] \u001b[1mnanoHUB.containers.dataaccess\u001b[0m [connection.get_connection_for:78]: Started SSH Tunnel with db2.nanohub.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,861| INFO    | Opening tunnel: 0.0.0.0:46683 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:30:05,861 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel._serve_forever_wrapper:1433]: Opening tunnel: 0.0.0.0:46683 <> 127.0.0.1:3306\n",
      "Obtained Salesforce access token ...... True\n"
     ]
    }
   ],
   "source": [
    "from nanoHUB.application import Application\n",
    "\n",
    "application = Application.get_instance()\n",
    "nanohub_db = application.new_db_engine('nanohub')\n",
    "nh_metrics_db = application.new_db_engine('nanohub_metrics')\n",
    "wang159_myrmekes_db = application.new_db_engine('wang159_myrmekes')\n",
    "\n",
    "salesforce = application.new_salesforce_engine()\n",
    "db_s = salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nanohub user growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need \n",
    "# 1) jos_users from nanohub with id,name,username,email,registerDate,lastvisitDate -> registered users\n",
    "# 2) toolstart df filtered by username -> simulation users\n",
    "\n",
    "# x-axis: each month from 2000 to 2019\n",
    "\n",
    "# y-axis: 12 month trailing sum\n",
    "\n",
    "# simulation users: unique users who have run at least 1 simulation\n",
    "\n",
    "# registered users: new user registeration\n",
    "\n",
    "# visitor count: unique IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build jos_users_full\n",
    "sql_query = \"select id,name,username,email,registerDate,lastvisitDate from jos_users order by registerDate desc\"\n",
    "jos_users_full = pd.read_sql_query(sql_query, nanohub_db)\n",
    "display(jos_users_full.head(2))\n",
    "print(jos_users_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build all users list\n",
    "sql_query = \"select datetime,ip,countryip,user,tool from toolstart where user != 'instanton' \"\\\n",
    "+\"and user != 'gridstat' and datetime <= '2002-01-01' and datetime >= '0000-01-01' order by datetime desc\"\n",
    "toolstart_df = pd.read_sql_query(sql_query, nh_metrics_db)\n",
    "display(toolstart_df.head(2))\n",
    "print(toolstart_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the dataframes to datetime\n",
    "jos_users_full['registerDate'] = pd.to_datetime(jos_users_full.registerDate)\n",
    "jos_users_full['lastvisitDate'] = pd.to_datetime(jos_users_full.lastvisitDate)\n",
    "\n",
    "toolstart_df['datetime'] = pd.to_datetime(toolstart_df.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months_list = list()\n",
    "for this_year in range(2000,2021+1):\n",
    "    for this_month in range(1,12+1):\n",
    "        all_months_list.append(datetime.datetime(this_year, this_month, 1))\n",
    "        \n",
    "for this_year in range(2021,2022):\n",
    "    for this_month in range(1,2):\n",
    "        all_months_list.append(datetime.datetime(this_year, this_month, 1))\n",
    "        \n",
    "months_bin = pd.DataFrame(all_months_list, columns=['year_month'])\n",
    "\n",
    "# display\n",
    "months_bin.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jos_users_full registration cumulative monthly\n",
    "months_bin['registered_12_trail'] = months_bin.year_month.apply(lambda x:  \\\n",
    "                                jos_users_full.username[(jos_users_full.registerDate < x)\\\n",
    "                            &(jos_users_full.registerDate > (x-datetime.timedelta(days=365)))].nunique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the all users must be done in a bi-yearly basis\n",
    "months_bin['sim_12_trail'] = months_bin.year_month.apply(lambda x: toolstart_df.user[(toolstart_df.datetime < x) \\\n",
    "                                        &(toolstart_df.datetime > (x-datetime.timedelta(days=365)))].nunique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(months_bin['year_month'].to_list().index(pd.to_datetime('2002-01-01')) )\n",
    "temp = months_bin['sim_12_trail']#[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[-5:])\n",
    "print(temp[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computer has memory limits, so split the sim_12_trail into batches\n",
    "start_year = 2002 #2002 #allows for flexibility as well for future updates\n",
    "\n",
    "while start_year < 2021:#datetime.datetime.now().year:\n",
    "    prev_temp_ind = months_bin['year_month'].to_list().index(pd.to_datetime(str(start_year)+'-01-01')) \n",
    "    \n",
    "    start_year += 1\n",
    "    end_date = r\"'\"+str(start_year)+r\"-01-01'\"\n",
    "#     print(end_date)\n",
    "    start_date = r\"'\"+str(start_year-2)+r\"-01-01'\"\n",
    "    \n",
    "    sql_query = \"select datetime,ip,countryip,user,tool from toolstart where user != 'instanton' \"\\\n",
    "        +\"and user != 'gridstat' and datetime <= \"+end_date+\" and datetime >= \"+start_date+\" order by datetime desc\"\n",
    "    toolstart_df = pd.read_sql_query(sql_query, engine_metrics)\n",
    "    toolstart_df['datetime'] = pd.to_datetime(toolstart_df.datetime)\n",
    "    print(toolstart_df.shape)\n",
    "    \n",
    "    temp2 = months_bin.year_month.apply(lambda x: toolstart_df.user[(toolstart_df.datetime < x) \\\n",
    "                                        &(toolstart_df.datetime > (x-datetime.timedelta(days=365)))].nunique() )\n",
    "    \n",
    "    max_temp_ind = months_bin['year_month'].to_list().index(pd.to_datetime(str(start_year)+'-01-01')) \n",
    "    \n",
    "    temp[prev_temp_ind:max_temp_ind] = temp2[prev_temp_ind:max_temp_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total number of visitors\n",
    "import json\n",
    "with open(cwd+'/visitors.json') as f:\n",
    "    visitor_dict = f.read()\n",
    "    visitor_dict = visitor_dict.replace(\"\\'\",'\\\"')\n",
    "    visitor_dict = json.loads(visitor_dict)\n",
    "#     visitor_dict.replace(r\"'\",r'\"')\n",
    "#     vicitor_dict = json.load(visitor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('\\d+]')\n",
    "step1 = re.findall(pattern,visitor_dict['data'])\n",
    "res_visitors = [i[:-1] for i in step1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res_visitors2 = list(np.zeros(12*6+14)) + res_visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(res_visitors2))\n",
    "print(res_visitors2[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(months_bin.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin['visitors_12_trail'] = res_visitors2\n",
    "# months_bin['sim_12_trail'] = temp\n",
    "display(months_bin.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(months_bin.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin.registered_12_trail[:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin.sim_12_trail[:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#months_bin.to_csv('months_bin_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "#plt.figure(figsize=(9,6))\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.clear()\n",
    "ax1.plot(months_bin.year_month[:-11], months_bin.registered_12_trail[:-11], color='red', label='Registered Users');\n",
    "ax1.plot(months_bin.year_month[:-11], months_bin.sim_12_trail[:-11], color='blue', label='Simulation Users');\n",
    "#plt.plot(months_bin.year_month,res_visitors2)\n",
    "\n",
    "ax1.set_title('nanoHUB user growth');\n",
    "\n",
    "ax1.set_xlim([datetime.datetime(2000,1,1), datetime.datetime(2021,3,1)]);\n",
    "ax1.set_ylim([0, 35000])\n",
    "ax1.set_yticks(np.arange(0,35000,5000))\n",
    "ax1.tick_params(axis='y',labelcolor='red')\n",
    "# ax1.set_ylabel('Unique Users/Month')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "# ax2.set_ylabel('Unique Visitors/Month')\n",
    "ax2.plot(months_bin.year_month[:-11],months_bin.visitors_12_trail[11:],color='green',label='Unique Monthly Visitors')\n",
    "ax2.tick_params(axis='y',labelcolor='green')\n",
    "ax2.set_yticks(np.arange(0,2000000+250000,250000))\n",
    "ax2.set_ylim([0,2000000+250000])\n",
    "# ax2.legend(loc='center left')\n",
    "# plt.ylabel('Annualized nanoHUB Visitors');\n",
    "# ax1.legend(loc='upper left');\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'/appendixF_plots/overall_user_growth_legend.eps', dpi=500, bbox_inches='tight')\n",
    "# plt.savefig(cwd+'/appendixF_plots/overall_user_growth_no_legend.png', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(months_bin.registered_12_trail[-13:-12])\n",
    "print(months_bin.sim_12_trail[-13:-12])\n",
    "print(months_bin.visitors_12_trail[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin.year_month[:-12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative classroom/research/self-study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# 1. pull all unique classroom users from SF\n",
    "# 2. pull all research users from DB2\n",
    "# 3. pull all contacts from SF\n",
    "# 4. iteratively pull toolstart df again by year starting from 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull all classroom users from SF\n",
    "db_1 = DB2SalesforceAPI(sf_login_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull the list of contacts within each cluster\n",
    "contacts_in_cluster_df = db_1.query_data('Select Contact__c, Tool_Usage_Cluster__c from ContactToolClusterAssociation__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(contacts_in_cluster_df.head(2))\n",
    "print(contacts_in_cluster_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if SF processing errors\n",
    "if contacts_in_cluster_df.shape[0] <= 100:\n",
    "    contacts_in_cluster_df = pd.read_csv(cwd+'/backup_contacts_in_clusters.csv')\n",
    "    contacts_in_cluster_df = contacts_in_cluster_df.drop(columns=['Unnamed: 0'])\n",
    "display(contacts_in_cluster_df.head(2))\n",
    "print(contacts_in_cluster_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contacts_in_clusters = set(contacts_in_cluster_df['Contact__c'].to_list())\n",
    "print(len(unique_contacts_in_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df = db_1.query_data('Select Id, nanoHUB_user_ID__c from Contact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(contacts_df.head(2))\n",
    "print(contacts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine self-study users, i.e., unclassified users\n",
    "# if sf id is in contacts_in_cluster_df['Contact__c'], then it is self-study\n",
    "\n",
    "self_study = []\n",
    "clustered = []\n",
    "\n",
    "sf_contact_ids = contacts_df['Id'].to_list()\n",
    "\n",
    "import numpy as np\n",
    "# bool_search = np.in1d(np.array(list(unique_contacts_in_clusters)),np.array(sf_contact_ids))\n",
    "bool_search = np.in1d(np.array(sf_contact_ids),np.array(list(unique_contacts_in_clusters)))\n",
    "\n",
    "clustered = np.where(bool_search)[0].tolist()\n",
    "self_study = np.where(~bool_search)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_NH_ids = contacts_df['nanoHUB_user_ID__c'][clustered]\n",
    "self_study_NH_ids = contacts_df['nanoHUB_user_ID__c'][self_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clustered_NH_ids.shape)\n",
    "print(self_study_NH_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to filter self-study-nh-ids with the researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull in research users\n",
    "import sqlalchemy as sql\n",
    "sql_query = \"select uidNumber from jos_citations_authors where uidNumber != 0\"\n",
    "engine = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))\n",
    "researcher_ids = pd.read_sql_query(sql_query, engine)\n",
    "display(researcher_ids.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_ids2 = researcher_ids.drop_duplicates()['uidNumber']\n",
    "researcher_ids2 = researcher_ids2.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(researcher_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_contact_ids = contacts_df['nanoHUB_user_ID__c'][self_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_contact_ids = sf_contact_ids.reset_index()\n",
    "sf_contact_ids = sf_contact_ids.drop(columns='index')\n",
    "display(sf_contact_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_search2 = np.in1d(np.array(sf_contact_ids['nanoHUB_user_ID__c'].to_list()),np.array(researcher_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researchers = np.where(bool_search2)[0].tolist()\n",
    "self_study2 = np.where(~bool_search2)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(researchers))\n",
    "print(len(self_study2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_NH_ids = pd.DataFrame(contacts_df['nanoHUB_user_ID__c'][clustered]) # already done\n",
    "self_study_NH_ids = pd.DataFrame(pd.DataFrame(sf_contact_ids).iloc[self_study2,:])\n",
    "researcher_NH_ids = pd.DataFrame(pd.DataFrame(sf_contact_ids).iloc[researchers,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_NH_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in toolstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching ids to usernames\n",
    "sql_query2 = \"select id,username from jos_users\"\n",
    "id_username_df = pd.read_sql_query(sql_query2, engine)\n",
    "display(id_username_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames_db2 = id_username_df['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cluster = np.in1d(usernames_db2,clustered_NH_ids['nanoHUB_user_ID__c'])\n",
    "clustered_NH_username = np.where(t_cluster)[0].tolist()\n",
    "clustered_NH_username2 = pd.DataFrame(id_username_df['username'][clustered_NH_username])\n",
    "display(clustered_NH_username2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_research = np.in1d(usernames_db2,researcher_NH_ids['nanoHUB_user_ID__c'])\n",
    "researcher_NH_username = np.where(t_research)[0].tolist()\n",
    "researcher_NH_username2 = pd.DataFrame(id_username_df['username'][researcher_NH_username])\n",
    "display(researcher_NH_username2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_self_study = np.in1d(usernames_db2,self_study_NH_ids['nanoHUB_user_ID__c'])\n",
    "self_NH_username = np.where(t_self_study)[0].tolist()\n",
    "self_NH_username2 = pd.DataFrame(id_username_df['username'][self_NH_username])\n",
    "display(self_NH_username2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustered_NH_username2;researcher_NH_username2;self_NH_username2\n",
    "clustered_track = []\n",
    "self_track = []\n",
    "researcher_track = []\n",
    "\n",
    "clustered_track_per = []\n",
    "self_track_per = []\n",
    "researcher_track_per = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_metrics = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub_metrics' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computer has memory limits, so split toolstart into branches\n",
    "start_year = 2000 #2002 #allows for flexibility as well for future updates\n",
    "\n",
    "while start_year < 2021:#datetime.datetime.now().year:\n",
    "    start_year += 1\n",
    "    end_date = r\"'\"+str(start_year)+r\"-01-01'\"\n",
    "#     print(end_date)\n",
    "    start_date = r\"'\"+str(start_year-2)+r\"-01-01'\"\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        if i < 10:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-0\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-0\"+str(i)+r\"-01'\"\n",
    "        else:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-\"+str(i)+r\"-01'\"\n",
    "        ## unique active users\n",
    "#         current = time.time()\n",
    "#         sql_query_clustered = \"select count(distinct user) from toolstart where user in \" + str(tuple(clustered_NH_username2['username']))\\\n",
    "#             +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "#         clustered_users = pd.read_sql_query(sql_query_clustered, engine_metrics)\n",
    "        \n",
    "#         sql_query_self = \"select count(distinct user) from toolstart where user in \" + str(tuple(self_NH_username2['username']))\\\n",
    "#             +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "#         self_users = pd.read_sql_query(sql_query_self, engine_metrics)\n",
    "        \n",
    "#         sql_query_researcher = \"select count(distinct user) from toolstart where user in \" + str(tuple(researcher_NH_username2['username']))\\\n",
    "#             +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "#         researcher_users = pd.read_sql_query(sql_query_researcher, engine_metrics)\n",
    "        \n",
    "        sql_query_clustered = \"select user from toolstart where user in \" + str(tuple(clustered_NH_username2['username']))\\\n",
    "            +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "        clustered_users = pd.read_sql_query(sql_query_clustered, engine_metrics)#.drop_duplicates()\n",
    "        \n",
    "        sql_query_self = \"select user from toolstart where user in \" + str(tuple(self_NH_username2['username']))\\\n",
    "            +\" and user != 'instanton' and user != 'gridstat' and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "        self_users = pd.read_sql_query(sql_query_self, engine_metrics)#.drop_duplicates()\n",
    "        \n",
    "        sql_query_researcher = \"select user from toolstart where user in \" + str(tuple(researcher_NH_username2['username']))\\\n",
    "            +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "        researcher_users = pd.read_sql_query(sql_query_researcher, engine_metrics)#.drop_duplicates()\n",
    "\n",
    "#         sql_query_all =  \"select user from toolstart where user not in ('gridstat','instanton')\" \\\n",
    "#             +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "#         all_users = pd.read_sql_query(sql_query_all, engine_metrics)#.drop_duplicates()\n",
    "#         print(time.time() - current)\n",
    "#         clustered_track.append(clustered_users['count(distinct user)'][0])\n",
    "#         self_track.append(self_users['count(distinct user)'][0])\n",
    "#         researcher_track.append(researcher_users['count(distinct user)'][0])\n",
    "\n",
    "        clustered_track.append(clustered_users.drop_duplicates().shape[0])\n",
    "        self_track.append(self_users.drop_duplicates().shape[0])\n",
    "        researcher_track.append(researcher_users.drop_duplicates().shape[0])\n",
    "\n",
    "#         clustered_track_per.append(clustered_users.shape[0]/all_users.shape[0])\n",
    "#         self_track_per.append(self_users.shape[0]/all_users.shape[0])\n",
    "#         researcher_track_per.append(researcher_users.shape[0]/all_users.shape[0])        \n",
    "        \n",
    "#         print(clustered_users)\n",
    "#         print(self_users)\n",
    "#         print(researcher_users)\n",
    "    print(start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_bin.year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakdown_df = pd.DataFrame()\n",
    "user_breakdown_df['year_month'] = months_bin['year_month'].to_list()[13:]\n",
    "user_breakdown_df['clustered_track'] = clustered_track\n",
    "user_breakdown_df['self_track'] = self_track\n",
    "user_breakdown_df['researcher_track'] = researcher_track\n",
    "user_breakdown_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.stackplot(user_breakdown_df.year_month, \\\n",
    "              user_breakdown_df[['clustered_track', 'self_track', 'researcher_track']].to_numpy().T, \\\n",
    "             labels=['classroom', 'self-study', 'research'], \\\n",
    "             colors=['green', 'orange', 'red']);\n",
    "\n",
    "plt.legend(loc='upper left');\n",
    "plt.ylabel('12-month trailing total')\n",
    "plt.xlim([datetime.datetime(2001,1,1), datetime.datetime(2021,1,1)])\n",
    "plt.ylim([0, 22000])\n",
    "\n",
    "# plt.savefig('./sim_user_by_type_1.svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakdown_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check researchers\n",
    "engine = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))\n",
    "\n",
    "sql_query = \"select uidNumber,givenName,surname from jos_citations_authors\"\n",
    "jos_citations_authors = pd.read_sql_query(sql_query, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jos_citations_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = 'select id, uid, author from jos_citations'\n",
    "jos_citations = pd.read_sql_query(sql_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jos_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_authors = jos_citations['author'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_authors2 = [] #[j.split(';') for i,j in enumerate(t1_authors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(t1_authors):\n",
    "    try:\n",
    "        holder = j.split(';')\n",
    "        if len(holder) > 1: \n",
    "            for k,l in enumerate(holder):\n",
    "                if l[0] == ' ':\n",
    "                    holder[k] = l[1:]\n",
    "        t1_authors2.append(holder)\n",
    "    except:\n",
    "        garb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_authors3 = [item for sublist in t1_authors2 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_authors3 = set(t1_authors3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t1_authors3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract all researchers with nh ids\n",
    "rw_ids = []\n",
    "need_search = []\n",
    "for i,j in enumerate(t1_authors3):\n",
    "    if '{{' in j:\n",
    "        rw_ids.append(i)\n",
    "    else:\n",
    "        need_search.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from the rw_ids, extract the nanohub userids\n",
    "# can obtain usernames from the DB2 table\n",
    "rw_ids2 = np.array(list(t1_authors3))[rw_ids]\n",
    "for i,j in enumerate(rw_ids2):\n",
    "    begin = j.index('{{')\n",
    "    rw_ids2[i] = j[begin+2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rw_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to obtain usernames\n",
    "sql_query = \"select id,name,username from jos_users where id in \"+str(tuple(rw_ids2))\n",
    "rw_researchers = pd.read_sql_query(sql_query,engine)\n",
    "display(rw_researchers.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to obtain the username/ids from those people without nh ids explicitly spec'd in jos_citations\n",
    "ns2 = np.array(list(t1_authors3))[need_search]\n",
    "ns2 = ns2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(ns2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select id,name,username from jos_users where name in \"+str(tuple(ns2))\n",
    "ns2_researchers = pd.read_sql_query(sql_query,engine)\n",
    "display(ns2_researchers.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine the usernames into one data structure\n",
    "researcher_usernames = rw_researchers['username'].to_list() + ns2_researchers['username'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(researcher_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_track = []\n",
    "engine_metrics = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub_metrics' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computer has memory limits, so split toolstart into branches\n",
    "start_year = 2000 #2002 #allows for flexibility as well for future updates\n",
    "\n",
    "while start_year < 2021:#datetime.datetime.now().year:\n",
    "    start_year += 1\n",
    "    end_date = r\"'\"+str(start_year)+r\"-01-01'\"\n",
    "#     print(end_date)\n",
    "    start_date = r\"'\"+str(start_year-2)+r\"-01-01'\"\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        if i < 10:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-0\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-0\"+str(i)+r\"-01'\"\n",
    "        else:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-\"+str(i)+r\"-01'\"\n",
    "\n",
    "        sql_query_researcher = \"select user from toolstart where user in \" + str(tuple(researcher_usernames))\\\n",
    "            +\" and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "        researcher_users = pd.read_sql_query(sql_query_researcher, engine_metrics)#.drop_duplicates()\n",
    "\n",
    "        researcher_track.append(researcher_users.drop_duplicates().shape[0])\n",
    "\n",
    "    print(start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakdown_df['researcher_track'] = researcher_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "# plt.figure(figsize=(6,6))\n",
    "user_breakdown_df2 = user_breakdown_df.iloc[:-11,:]\n",
    "plt.stackplot(user_breakdown_df2.year_month, \\\n",
    "              user_breakdown_df2[['clustered_track', 'researcher_track','self_track']].to_numpy().T, \\\n",
    "             labels=['Classroom','Research', 'Unclassified'], \\\n",
    "             colors=['green', 'red', 'orange']); #Self-study\n",
    "\n",
    "plt.legend(loc='upper left')#,fontsize=14);\n",
    "plt.ylabel('12-month Trailing Total')#,fontsize=15)\n",
    "\n",
    "plt.xlim([datetime.datetime(2001,1,1), datetime.datetime(2021,2,1)])#,fontsize=15)\n",
    "\n",
    "# test = plt.xticks()\n",
    "# # print(test)\n",
    "# # print([i.get_text() for i in test[1]])\n",
    "# plt.xticks(ticks=test[0][1:-1],labels=[str(i) for i in range(2002,2021,2)],fontsize=14)\n",
    "# # plt.xticks(ticks=['2001:1:1','2021:1:1'])#list(range(2000,2021,2)))#, \\\n",
    "# #     labels=list(range(2000,2021,2)),fontsize=12)\n",
    "\n",
    "# test_y = plt.yticks()\n",
    "# plt.yticks(ticks=test_y[0][0:-1],labels=[str(i) for i in range(0,21000,5000)],fontsize=14)\n",
    "\n",
    "# plt.xlim_labels('')\n",
    "# plt.ylim([0, 24000],fontsize=15)\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_type.png', dpi=500,bbox_inches='tight')\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_type.eps',bbox_inches='tight')\n",
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_type_HICSS.png', dpi=1500,bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakdown_df2['clustered_track'].to_list()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakdown_df2['clustered_track_per'] = 100*np.divide(user_breakdown_df2['clustered_track'],\\\n",
    "            user_breakdown_df2['clustered_track'].to_numpy()+user_breakdown_df2['researcher_track'].to_numpy()+\\\n",
    "                        user_breakdown_df2['self_track'].to_numpy())\n",
    "user_breakdown_df2['researcher_track_per'] = 100*np.divide(user_breakdown_df2['researcher_track'],\\\n",
    "            user_breakdown_df2['clustered_track'].to_numpy()+user_breakdown_df2['researcher_track'].to_numpy()+\\\n",
    "                        user_breakdown_df2['self_track'].to_numpy())\n",
    "user_breakdown_df2['self_track_per'] = 100*np.divide(user_breakdown_df2['self_track'],\\\n",
    "            user_breakdown_df2['clustered_track'].to_numpy()+user_breakdown_df2['researcher_track'].to_numpy()+\\\n",
    "                        user_breakdown_df2['self_track'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(user_breakdown_df2.year_month, user_breakdown_df2.clustered_track_per, label='classroom', \\\n",
    "             color='green');\n",
    "plt.plot(user_breakdown_df2.year_month, user_breakdown_df2.researcher_track_per, label='research', \\\n",
    "             color='red');\n",
    "plt.plot(user_breakdown_df2.year_month, user_breakdown_df2.self_track_per, label='self-study', \\\n",
    "             color='orange');\n",
    "\n",
    "plt.ylim([0, 100])\n",
    "plt.legend(loc='upper right');\n",
    "plt.ylabel('Percentage (%)');\n",
    "plt.xlim([datetime.datetime(2001,1,1), datetime.datetime(2021,2,1)])\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_type_per.png', dpi=500,bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/sim_user_by_type_per.eps',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: active simulation users by geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to do iterative importing once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_metrics = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub_metrics' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame()\n",
    "country_df['year_month'] = months_bin['year_month'].to_list()[13:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = []\n",
    "china = []\n",
    "eu = []\n",
    "india = []\n",
    "other = []\n",
    "eu_list = ['BE','BG','EL','CZ','DK','DE','EE','IE','ES','FR','HR','IT','CY','LV',\\\n",
    "          'LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE','IS',\\\n",
    "           'NO','LI','CH','UK','ME','MK','AL','RS','TR','BA','XK','AM','AZ','BY',\\\n",
    "           'MD','GE','UA','RU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computer has memory limits, so split toolstart into branches\n",
    "start_year = 2000 #2002 #allows for flexibility as well for future updates\n",
    "\n",
    "while start_year < 2021:#datetime.datetime.now().year:\n",
    "    start_year += 1\n",
    "#     end_date = r\"'\"+str(start_year)+r\"-01-01'\"\n",
    "# #     print(end_date)\n",
    "#     start_date = r\"'\"+str(start_year-1)+r\"-01-01'\"\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        if i < 10:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-0\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-0\"+str(i)+r\"-01'\"\n",
    "        else:\n",
    "            start_date = r\"'\"+str(start_year-1)+r\"-\"+str(i)+r\"-01'\"\n",
    "            end_date = r\"'\"+str(start_year)+r\"-\"+str(i)+r\"-01'\"\n",
    "\n",
    "        sql_query_country = \"select distinct user, countryip from toolstart where user != 'instanton' \"\\\n",
    "        + \"and user != 'gridstat' and datetime <= \"+end_date+\" and datetime >= \"+start_date\n",
    "        country_users = pd.read_sql_query(sql_query_country, engine_metrics)#.drop_duplicates()\n",
    "        \n",
    "        # run geography filter\n",
    "        country_ipds = country_users['countryip'].to_list()\n",
    "        \n",
    "        bool_US = np.in1d(np.array(country_ipds),np.array(['US']))\n",
    "        bool_EU = np.in1d(np.array(country_ipds),np.array(eu_list))\n",
    "        bool_CN = np.in1d(np.array(country_ipds),np.array(['CN']))\n",
    "        bool_IN = np.in1d(np.array(country_ipds),np.array(['IN']))\n",
    "#         bool_OT = bool_US | bool_EU | bool_CN | bool_IN\n",
    "        \n",
    "        usa.append(len(np.where(bool_US)[0].tolist()))\n",
    "        eu.append(len(np.where(bool_EU)[0].tolist()))\n",
    "        china.append(len(np.where(bool_CN)[0].tolist()))\n",
    "        india.append(len(np.where(bool_IN)[0].tolist()))\n",
    "        other.append(len(country_ipds)-usa[-1]-eu[-1]-china[-1]-india[-1]) # len(np.where(bool_OT)[0].tolist()))\n",
    "        \n",
    "#         country_users.append(country_users.drop_duplicates().shape[0])\n",
    "\n",
    "    print(start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(usa))\n",
    "usa2 = usa[37:-8]\n",
    "print(len(usa2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df['USA'] = usa[37:-8]\n",
    "country_df['China'] = china[37:-8]\n",
    "country_df['Europe'] = eu[37:-8]\n",
    "country_df['India'] = india[37:-8]\n",
    "country_df['Other'] = other[37:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df['Total'] = np.array(usa[37:-8])+np.array(china[37:-8])+np.array(eu[37:-8])+np.array(india[37:-8])+np.array(other[37:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plt.stackplot(country_df['year_month'], \\\n",
    "              country_df[['USA', 'China', 'India', 'Europe', 'Other']].to_numpy().T, \\\n",
    "             labels=country_df.columns.to_list()[1:-1], \\\n",
    "             colors=['blue', 'red', 'orange', 'green', 'black']);\n",
    "\n",
    "plt.legend(loc='upper left');\n",
    "plt.ylabel('12-month trailing total')\n",
    "plt.xlim([datetime.datetime(2002,1,1), datetime.datetime(2021,2,1)]);\n",
    "plt.ylim([0, 25000])\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_country.png', dpi=500,bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/sim_user_by_country.eps',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(country_df['year_month'], \\\n",
    "         country_df['USA'].to_numpy()/country_df['Total'].to_numpy() *100\\\n",
    "         , label='US', color='blue');\n",
    "plt.plot(country_df['year_month'], \\\n",
    "         country_df['China'].to_numpy()/country_df['Total'].to_numpy() *100\\\n",
    "         , label='China', color='red');\n",
    "plt.plot(country_df['year_month'], \\\n",
    "         country_df['India'].to_numpy()/country_df['Total'].to_numpy() *100\\\n",
    "         , label='India', color='orange');\n",
    "plt.plot(country_df['year_month'], \\\n",
    "         country_df['Europe'].to_numpy()/country_df['Total'].to_numpy() *100\\\n",
    "         , label='Europe', color='green');\n",
    "plt.plot(country_df['year_month'], \\\n",
    "         country_df['Other'].to_numpy()/country_df['Total'].to_numpy() *100\\\n",
    "         , label='Others', color='black');\n",
    "\n",
    "plt.xlim([datetime.datetime(2001,1,1), datetime.datetime(2021,2,1)])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend(loc='upper right');\n",
    "plt.ylabel('Percentage (%)')\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/sim_user_by_country_perc.png', dpi=500,bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/sim_user_by_country_perc.eps',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classroom activity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## students and classes per semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull all classroom users from SF\n",
    "db_1 = DB2SalesforceAPI(sf_login_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull the list of contacts within each cluster\n",
    "contacts_in_cluster_df = db_1.query_data('Select Id, Contact__c, Tool_Usage_Cluster__c from ContactToolClusterAssociation__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_in_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_in_cluster_df = pd.read_csv(cwd+'/backup_contacts_in_clusters.csv')\n",
    "contacts_in_cluster_df = contacts_in_cluster_df.drop(columns=['Unnamed: 0'])\n",
    "contacts_in_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = db_1.query_data('Select id, ID__c, Semester__c, Ending_Date__c, Starting_Date__c from tool_usage_cluster__c')\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv(cwd+'/backup_tool_cluster_df.csv')\n",
    "clusters_df = clusters_df.drop(columns=['Unnamed: 0'])\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter by starting_date__c\n",
    "cluster_dts = pd.to_datetime(clusters_df['Starting_Date__c'])\n",
    "\n",
    "## don't use current year's data\n",
    "cluster_dts2 = clusters_df[cluster_dts <= '2021-01-01']\n",
    "cluster_dts2 = cluster_dts2.reset_index()['index'].to_list()\n",
    "display(cluster_dts2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df2 = clusters_df.iloc[cluster_dts2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df2 = clusters_df2.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate classes per semester\n",
    "clusters_df2['Starting_Date__c'] = pd.to_datetime(clusters_df2['Starting_Date__c'])\n",
    "\n",
    "starting_year = 2000\n",
    "\n",
    "semester_list = ['Spring','Fall','Summer']\n",
    "# group Spring and Summer togethre\n",
    "\n",
    "months_sems = []\n",
    "\n",
    "while starting_year < 2022:\n",
    "    for i in semester_list:\n",
    "        if i == 'Fall':\n",
    "            months_sems.append(datetime.datetime.strptime(str(starting_year)+'-07-01', '%Y-%m-%d') )\n",
    "        elif i == 'Spring':\n",
    "            months_sems.append(datetime.datetime.strptime(str(starting_year)+'-01-01', '%Y-%m-%d') )\n",
    "    starting_year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids_per_sem = {}\n",
    "for i,j in enumerate(months_sems):\n",
    "    if i == 0:\n",
    "        cluster_ids_per_sem[i] = clusters_df2['Id'].to_numpy()[clusters_df2['Starting_Date__c'] < months_sems[i+1]]\n",
    "    elif i == len(months_sems)-1:\n",
    "        cluster_ids_per_sem[i] = clusters_df2['Id'].to_numpy()[(clusters_df2['Starting_Date__c'] > j)]\n",
    "    else:\n",
    "        cluster_ids_per_sem[i] = clusters_df2['Id'].to_numpy()[(clusters_df2['Starting_Date__c'] > j) \\\n",
    "                        & (clusters_df2['Starting_Date__c'] < months_sems[i+1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## produce classes sizes per semester\n",
    "cluster_ids_per_sem_nums = [len(i) for i in cluster_ids_per_sem.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find overlaps\n",
    "# ttt = np.in1d(np.array(clusters_df['Id']),np.array(contacts_in_cluster_df['Tool_Usage_Cluster__c']))\n",
    "# len(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the student populations per semester\n",
    "students = []\n",
    "students_count = []\n",
    "for i in cluster_ids_per_sem.values():\n",
    "    bool_students = np.in1d(np.array(contacts_in_cluster_df['Tool_Usage_Cluster__c'].to_list()),np.array(i))\n",
    "    \n",
    "    students.append(contacts_in_cluster_df['Contact__c'].to_numpy()[np.where(bool_students)[0]]) #dataframe indexes\n",
    "    students_count.append(len(students[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_sems2 = [str(i.year)+'-0'+str(i.month) for i in months_sems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot two bar plots\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "g = sns.barplot(months_sems2, cluster_ids_per_sem_nums, color='blue');\n",
    "g.set_xticklabels(months_sems2, rotation=90)\n",
    "\n",
    "plt.xlabel('Semester')\n",
    "plt.ylabel('Classes')\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/class_by_semester_count.png', dpi=500,bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/class_by_semester_count.eps',bbox_inches='tight')\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "g = sns.barplot(months_sems2, students_count, color='green');\n",
    "g.set_xticklabels(months_sems2, rotation=90)\n",
    "\n",
    "plt.xlabel('Semester')\n",
    "plt.ylabel('Students')\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/student_by_semester_count.png', dpi=500, bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/student_by_semester_count.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine cumulative uniques\n",
    "#students\n",
    "cumulative_sem_students = []\n",
    "unique_students = []\n",
    "cumulative_classes = []\n",
    "\n",
    "for i,j in enumerate(students):\n",
    "    if i == 0:\n",
    "        unique_students.append(len(set(j)))\n",
    "        cumulative_sem_students.append(students_count[i])\n",
    "        cumulative_classes.append(cluster_ids_per_sem_nums[i])\n",
    "    elif i == len(students)-1:\n",
    "        unique_students.append(len(set(np.concatenate(students[:i+1]))))\n",
    "        cumulative_sem_students.append(students_count[i] + cumulative_sem_students[-1])\n",
    "        cumulative_classes.append(cluster_ids_per_sem_nums[i] + cumulative_classes[-1])\n",
    "    else:\n",
    "        unique_students.append(len(set(np.concatenate(students[:i+1]))))\n",
    "        cumulative_sem_students.append(students_count[i]+cumulative_sem_students[-1])  \n",
    "        cumulative_classes.append(cluster_ids_per_sem_nums[i] + cumulative_classes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_year = 2001\n",
    "\n",
    "semester_list = ['Spring','Fall','Summer']\n",
    "# group Spring and Summer togethre\n",
    "\n",
    "months_sems3 = [datetime.datetime(2000, 7, 1, 0, 0)]\n",
    "\n",
    "while starting_year < 2022:\n",
    "    for i in semester_list:\n",
    "        if i == 'Fall':\n",
    "            months_sems3.append(datetime.datetime.strptime(str(starting_year)+'-07-01', '%Y-%m-%d') )\n",
    "        elif i == 'Spring':\n",
    "            months_sems3.append(datetime.datetime.strptime(str(starting_year)+'-01-01', '%Y-%m-%d') )\n",
    "    starting_year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(months_sems3[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_students = list(np.concatenate(students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "intermed_student = [len(list(group)) for key, group in groupby(duplicate_students)]\n",
    "np.where(np.array(intermed_student) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for key,group in groupby(duplicate_students):\n",
    "    counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cumulative_sem_students[-1],unique_students[-1],cumulative_classes[-1])\n",
    "print(cluster_ids_per_sem_nums[-1],len(set(np.concatenate(students[-1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## percent diff\n",
    "(89730-60357)/89730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cumulative class and student count\n",
    "fig, ax1 = plt.subplots(figsize=(9,6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_ylabel('Persons', color=color)\n",
    "#ax1.plot(class_students_count.cumsum(), color=color)\n",
    "ax1.plot(months_sems3[:-1], \\\n",
    "         cumulative_sem_students, color='Green')\n",
    "ax1.plot(months_sems3[:-1], unique_students, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Classes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(months_sems3[:-1],cumulative_classes, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.xlim([datetime.datetime(2000,7,1), datetime.datetime(2021,1,1)])\n",
    "\n",
    "ax1.set_ylim([0, 95000])\n",
    "ax1.grid(False)\n",
    "ax2.set_ylim([0, 8000])\n",
    "ax2.grid(False)\n",
    "\n",
    "# plt.savefig(cwd+'/appendixF_plots/student_class_count.png', dpi=500, bbox_inches='tight')\n",
    "plt.savefig(cwd+'/appendixF_plots/student_class_count.eps', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Lifetime Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull jos_users with the previously found self-study, classroom, and research users\n",
    "#then just compare the register vs last visit date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select registerDate, lastvisitDate from jos_users where username in \" + str(tuple(clustered_NH_username2['username']))\n",
    "engine = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_dates = pd.read_sql_query(sql_query,engine)\n",
    "clustered_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_dates[clustered_dates['lastvisitDate'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine time diffs\n",
    "clustered_dates2 = clustered_dates[~clustered_dates['lastvisitDate'].isna()].reset_index()\n",
    "clustered_dates2['registerDate'] = pd.to_datetime(clustered_dates2['registerDate'])\n",
    "clustered_dates2['lastvisitDate'] = pd.to_datetime(clustered_dates2['lastvisitDate'])\n",
    "clustered_dates2['duration'] = clustered_dates2['lastvisitDate'].to_numpy() - clustered_dates2['registerDate'].to_numpy()\n",
    "display(clustered_dates2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_dates2['duration'] = [np.round(np.log10(i.days),2) for i in clustered_dates2['duration'].to_list()]\n",
    "display(clustered_dates2.head(2))\n",
    "display(clustered_dates2.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 bins - log days\n",
    "max_log_interval = 4 #base 10\n",
    "bins = 50\n",
    "# 1 day, 2 day, 3 day, 4, 5, 6, 1 week, 2 week, 1 month, 2 month, 1 year, \n",
    "bin_vals = [np.round(4/50*(i+1),2) for i in range(bins)] #these are the ending bin vals\n",
    "bin_vals2 = [np.round(4/50*(i+1),2) for i in range(bins)] #these are the ending bin vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_user_vals = []\n",
    "for i,j in enumerate(bin_vals):\n",
    "    if i == 0:\n",
    "#         clustered_user_vals.append(clustered_dates[clustered_dates['lastvisitDate'].isna()].shape[0]\\\n",
    "#                                   +len(np.where(clustered_dates2['duration'] == 1)[0]))\n",
    "        h_thresh = j\n",
    "        l_thresh = 0\n",
    "        clustered_user_vals.append(len(np.where((clustered_dates2['duration'] < h_thresh))[0]))\n",
    "    else:\n",
    "        h_thresh = j\n",
    "        l_thresh = bin_vals[i-1]\n",
    "        clustered_user_vals.append(len(np.where((clustered_dates2['duration'] > l_thresh) \\\n",
    "                                    & (clustered_dates2['duration'] < h_thresh))[0]))        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_user_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_user_vals2 = []\n",
    "for i in clustered_user_vals:\n",
    "    if i != 0:\n",
    "        clustered_user_vals2.append(np.log10(i))\n",
    "    else:\n",
    "        clustered_user_vals2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(bin_vals2,bins=bin_vals2,weights=clustered_user_vals,align='left',color='green')\n",
    "plt.xlabel('User Lifetime (log days)')\n",
    "plt.xticks(np.arange(0,4.5,0.5))\n",
    "plt.ylim([0,2500])\n",
    "plt.ylabel('# of Users (log)')\n",
    "\n",
    "\n",
    "plt.savefig('classroom_users_hist.eps',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select registerDate, lastvisitDate from jos_users where username in \" + str(tuple(self_NH_username2['username']))\n",
    "engine = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_study_dates = pd.read_sql_query(sql_query,engine)\n",
    "self_study_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine time diffs\n",
    "self_study_dates2 = self_study_dates[~self_study_dates['lastvisitDate'].isna()].reset_index()\n",
    "self_study_dates2['registerDate'] = pd.to_datetime(self_study_dates2['registerDate'])\n",
    "self_study_dates2['lastvisitDate'] = pd.to_datetime(self_study_dates2['lastvisitDate'])\n",
    "self_study_dates2['duration'] = self_study_dates2['lastvisitDate'].to_numpy() - self_study_dates2['registerDate'].to_numpy()\n",
    "display(self_study_dates2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_study_dates2['duration'] = [np.round(np.log10(i.days),2) for i in self_study_dates2['duration'].to_list()]\n",
    "display(self_study_dates2.head(2))\n",
    "display(self_study_dates2.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_user_vals = []\n",
    "for i,j in enumerate(bin_vals):\n",
    "    if i == 0:\n",
    "#         clustered_user_vals.append(clustered_dates[clustered_dates['lastvisitDate'].isna()].shape[0]\\\n",
    "#                                   +len(np.where(clustered_dates2['duration'] == 1)[0]))\n",
    "        h_thresh = j\n",
    "        l_thresh = 0\n",
    "        self_user_vals.append(len(np.where((self_study_dates2['duration'] < h_thresh))[0]))\n",
    "    else:\n",
    "        h_thresh = j\n",
    "        l_thresh = bin_vals[i-1]\n",
    "        self_user_vals.append(len(np.where((self_study_dates2['duration'] > l_thresh) \\\n",
    "                                    & (self_study_dates2['duration'] < h_thresh))[0]))        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_user_vals[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(bin_vals2,bins=bin_vals2,weights=self_user_vals,align='left',color='orange')\n",
    "plt.xlabel('User Lifetime (log days)')\n",
    "plt.xticks(np.arange(0,4.5,0.5))\n",
    "plt.ylim([0,2500])\n",
    "plt.ylabel('# of Users')\n",
    "\n",
    "\n",
    "plt.savefig('self_users_hist.eps',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select registerDate, lastvisitDate from jos_users where username in \" + str(tuple(researcher_usernames))\n",
    "engine = sql.create_engine('mysql+pymysql://%s:%s@127.0.0.1/nanohub' \\\n",
    "                                               %('wang2506_ro', 'fnVnwcCS7iT45EsA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_dates = pd.read_sql_query(sql_query,engine)\n",
    "researcher_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine time diffs\n",
    "researcher_dates2 = researcher_dates[~researcher_dates['lastvisitDate'].isna()].reset_index()\n",
    "researcher_dates2['registerDate'] = pd.to_datetime(researcher_dates2['registerDate'])\n",
    "researcher_dates2['lastvisitDate'] = pd.to_datetime(researcher_dates2['lastvisitDate'])\n",
    "researcher_dates2['duration'] = researcher_dates2['lastvisitDate'].to_numpy() - researcher_dates2['registerDate'].to_numpy()\n",
    "display(researcher_dates2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_dates2['duration'] = [np.round(np.log10(i.days),2) for i in researcher_dates2['duration'].to_list()]\n",
    "display(researcher_dates2.head(2))\n",
    "display(researcher_dates2.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_vals = []\n",
    "for i,j in enumerate(bin_vals):\n",
    "    if i == 0:\n",
    "#         clustered_user_vals.append(clustered_dates[clustered_dates['lastvisitDate'].isna()].shape[0]\\\n",
    "#                                   +len(np.where(clustered_dates2['duration'] == 1)[0]))\n",
    "        h_thresh = j\n",
    "        l_thresh = 0\n",
    "        researcher_vals.append(len(np.where((researcher_dates2['duration'] < h_thresh))[0]))\n",
    "    else:\n",
    "        h_thresh = j\n",
    "        l_thresh = bin_vals[i-1]\n",
    "        researcher_vals.append(len(np.where((researcher_dates2['duration'] > l_thresh) \\\n",
    "                                    & (researcher_dates2['duration'] < h_thresh))[0]))        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_vals[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(bin_vals2,bins=bin_vals2,weights=researcher_vals,align='left',color='red')\n",
    "plt.xlabel('User Lifetime (log days)')\n",
    "plt.xticks(np.arange(0,4.5,0.5))\n",
    "plt.ylim([0,200])\n",
    "plt.ylabel('# of Users')\n",
    "\n",
    "\n",
    "plt.savefig('research_users_hist.eps',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_NH_username2['username'].to_csv(\"clustered_users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_NH_username2['username'].to_csv('self_study_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_temp = pd.DataFrame()\n",
    "tt_temp['usernames'] = researcher_usernames\n",
    "tt_temp.to_csv('researchers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
