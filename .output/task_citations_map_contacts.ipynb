{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f50ef0",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae6619",
   "metadata": {
    "papermill": {
     "duration": 0.057676,
     "end_time": "2021-08-26T03:54:03.095800",
     "exception": false,
     "start_time": "2021-08-26T03:54:03.038124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DB2-Salesforce connector: Citation mapping to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a338ba85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:03.222608Z",
     "iopub.status.busy": "2021-08-26T03:54:03.221762Z",
     "iopub.status.idle": "2021-08-26T03:54:06.281569Z",
     "shell.execute_reply": "2021-08-26T03:54:06.282001Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.127505,
     "end_time": "2021-08-26T03:54:06.282254",
     "exception": false,
     "start_time": "2021-08-26T03:54:03.154749",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mnanoHUB - Serving Students, Researchers & Instructors\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,229| INFO    | 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,229 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_agent_keys:1060]: 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,232| INFO    | 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,232 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_keys:1117]: 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,233| INFO    | Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,233 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.__init__:978]: Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,235 - [\u001b[1mINFO\u001b[0m] \u001b[1mnanoHUB.containers.dataaccess\u001b[0m [connection.get_connection_for:101]: Started SSH Tunnel with db2.nanohub.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,538| INFO    | Opening tunnel: 0.0.0.0:52123 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,538 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel._serve_forever_wrapper:1433]: Opening tunnel: 0.0.0.0:52123 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,564| INFO    | 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,564 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_agent_keys:1060]: 0 keys loaded from agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,567| INFO    | 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,567 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.get_keys:1117]: 0 key(s) loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,569| INFO    | Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,569 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel.__init__:978]: Connecting to gateway: db2.nanohub.org:22 as user 'saxenap'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,571 - [\u001b[1mINFO\u001b[0m] \u001b[1mnanoHUB.containers.dataaccess\u001b[0m [connection.get_connection_for:101]: Started SSH Tunnel with db2.nanohub.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,878| INFO    | Opening tunnel: 0.0.0.0:52126 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:54:05,878 - [INFO] sshtunnel.SSHTunnelForwarder [sshtunnel._serve_forever_wrapper:1433]: Opening tunnel: 0.0.0.0:52126 <> 127.0.0.1:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Salesforce access token ...... True\n"
     ]
    }
   ],
   "source": [
    "# API settings\n",
    "api_url = '/services/data/v43.0/sobjects'\n",
    "external_id = 'Name'\n",
    "object_id = 'contact_citation_asso__c'\n",
    "\n",
    "from nanoHUB.application import Application\n",
    "\n",
    "application = Application.get_instance()\n",
    "nanohub_db = application.new_db_engine('nanohub')\n",
    "wang159_myrmekes_db = application.new_db_engine('wang159_myrmekes')\n",
    "\n",
    "salesforce = application.new_salesforce_engine()\n",
    "db_s = salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303ef3c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:06.428756Z",
     "iopub.status.busy": "2021-08-26T03:54:06.428126Z",
     "iopub.status.idle": "2021-08-26T03:54:06.430039Z",
     "shell.execute_reply": "2021-08-26T03:54:06.430431Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.080123,
     "end_time": "2021-08-26T03:54:06.430598",
     "exception": false,
     "start_time": "2021-08-26T03:54:06.350475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/users/wang2506/nanohub_salesforce_integ/salesforce')\n",
    "    \n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b742d1",
   "metadata": {
    "papermill": {
     "duration": 0.074565,
     "end_time": "2021-08-26T03:54:06.574307",
     "exception": false,
     "start_time": "2021-08-26T03:54:06.499742",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Obtain tool information from DB2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4216d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:06.723435Z",
     "iopub.status.busy": "2021-08-26T03:54:06.722744Z",
     "iopub.status.idle": "2021-08-26T03:54:08.590521Z",
     "shell.execute_reply": "2021-08-26T03:54:08.590902Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.943259,
     "end_time": "2021-08-26T03:54:08.591067",
     "exception": false,
     "start_time": "2021-08-26T03:54:06.647808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Citations\n",
    "sql_query = \"select * from jos_citations\"\n",
    "\n",
    "citations_df = pd.read_sql_query(sql_query, nanohub_db)\n",
    "\n",
    "# Citation authors\n",
    "sql_query = \"select * from jos_citations_authors;\"\n",
    "\n",
    "authors_df = pd.read_sql_query(sql_query, nanohub_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b124fcd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:08.734756Z",
     "iopub.status.busy": "2021-08-26T03:54:08.734134Z",
     "iopub.status.idle": "2021-08-26T03:54:08.736025Z",
     "shell.execute_reply": "2021-08-26T03:54:08.736441Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.076818,
     "end_time": "2021-08-26T03:54:08.736669",
     "exception": false,
     "start_time": "2021-08-26T03:54:08.659851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace N/A and empty values with None\n",
    "authors_df.organization.replace('N/A', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d51f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:08.882481Z",
     "iopub.status.busy": "2021-08-26T03:54:08.881816Z",
     "iopub.status.idle": "2021-08-26T03:54:08.885178Z",
     "shell.execute_reply": "2021-08-26T03:54:08.885552Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.07824,
     "end_time": "2021-08-26T03:54:08.885717",
     "exception": false,
     "start_time": "2021-08-26T03:54:08.807477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'cid', 'author', 'authorid', 'uidNumber', 'ordering', 'givenName',\n",
       "       'middleName', 'surname', 'organization', 'org_dept', 'orgtype',\n",
       "       'countryresident', 'email', 'ip', 'host', 'countrySHORT', 'countryLONG',\n",
       "       'ipREGION', 'ipCITY', 'ipLATITUDE', 'ipLONGITUDE', 'in_network',\n",
       "       'orcid', 'research_id', 'gscholar_id', 'scopus_id', 'researchgate_id',\n",
       "       'notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61df9f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:09.044311Z",
     "iopub.status.busy": "2021-08-26T03:54:09.043687Z",
     "iopub.status.idle": "2021-08-26T03:54:09.060804Z",
     "shell.execute_reply": "2021-08-26T03:54:09.061183Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.096792,
     "end_time": "2021-08-26T03:54:09.061389",
     "exception": false,
     "start_time": "2021-08-26T03:54:08.964597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation_ID</th>\n",
       "      <th>nanohub_user_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>organization</th>\n",
       "      <th>orcid</th>\n",
       "      <th>research_id</th>\n",
       "      <th>gscholar_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000003</td>\n",
       "      <td>10676</td>\n",
       "      <td>4613</td>\n",
       "      <td>Purdue University</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000003</td>\n",
       "      <td>0</td>\n",
       "      <td>4614</td>\n",
       "      <td>Purdue University</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>37033</td>\n",
       "      <td>4615</td>\n",
       "      <td>Purdue University</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citation_ID  nanohub_user_id  author_id       organization orcid  \\\n",
       "0     10000003            10676       4613  Purdue University  None   \n",
       "1     10000003                0       4614  Purdue University  None   \n",
       "2     10000003            37033       4615  Purdue University  None   \n",
       "\n",
       "  research_id gscholar_id  \n",
       "0        None        None  \n",
       "1        None        None  \n",
       "2        None        None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining authors and citations\n",
    "ac_df = pd.merge(citations_df[['id']], authors_df[['cid', 'uidNumber','id','organization','orcid','research_id','gscholar_id']], how='inner',\\\n",
    "                 left_on='id', right_on='cid', suffixes=['_c', '_a'])\\\n",
    "                .drop(columns='id_c')\n",
    "\n",
    "ac_df.rename(columns={'cid':'citation_ID', 'uidNumber':'nanohub_user_id', 'id_a':'author_id'}, inplace=True)\n",
    "\n",
    "# display\n",
    "ac_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0458a6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:54:09.204761Z",
     "iopub.status.busy": "2021-08-26T03:54:09.204026Z",
     "iopub.status.idle": "2021-08-26T03:57:52.208150Z",
     "shell.execute_reply": "2021-08-26T03:57:52.208773Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 223.077378,
     "end_time": "2021-08-26T03:57:52.208984",
     "exception": false,
     "start_time": "2021-08-26T03:54:09.131606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain company domain information from DB2\n",
    "domain_df = pd.read_sql_query(\"select name as domain_name, domain, industry, `size range` as size, country \\\n",
    "from wang159_myrmekes.companies_email_domain\", wang159_myrmekes_db)\n",
    "\n",
    "# make sure domain is unique and drop NaN\n",
    "domain_df = domain_df.drop_duplicates(subset='domain', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36148cda",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7fa633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T03:57:52.396773Z",
     "iopub.status.busy": "2021-08-26T03:57:52.395844Z",
     "iopub.status.idle": "2021-08-26T03:57:53.972924Z",
     "shell.execute_reply": "2021-08-26T03:57:53.971871Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.669964,
     "end_time": "2021-08-26T03:57:53.973233",
     "exception": true,
     "start_time": "2021-08-26T03:57:52.303269",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/saxenap/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/share/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/saxenap/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/share/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/64/2zrjfqsn7x3fxjzpq46kqcyr0000gp/T/ipykernel_12263/668338128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ms_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nanohub/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/saxenap/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/share/nltk_data'\n    - '/Users/saxenap/.virtualenvs/nanohub/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "s_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbdb93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_domain(this_domain_name):\n",
    "    \n",
    "    if not this_domain_name:\n",
    "        return None\n",
    "    \n",
    "    # Replace all non-alphanumeric characters with space\n",
    "    this_domain_name = re.sub(\"[^0-9a-zA-Z]+\", \" \", this_domain_name.lower())\n",
    "    name_list = this_domain_name.split(' ')\n",
    "        \n",
    "    # remove all stop words\n",
    "    name_list = ['' if x in s_words else x for x in name_list]\n",
    "    \n",
    "    return set(filter(None, name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4016c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean domain name\n",
    "domain_df['domain_cleaned_set'] = domain_df.domain_name.apply(clean_domain)\n",
    "\n",
    "# hash cleaned domain name\n",
    "domain_df['domain_cleaned_hash'] = domain_df['domain_cleaned_set'].apply(lambda x: '-'.join(sorted(list(x))) if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7dda9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean domain name\n",
    "ac_df['domain_cleaned_set'] = ac_df.organization.apply(clean_domain)\n",
    "\n",
    "# hash cleaned domain name\n",
    "ac_df['domain_cleaned_hash'] = ac_df['domain_cleaned_set'].apply(lambda x: '-'.join(sorted(list(x))) if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd02085",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get domain subset that contains domain_cleaned_hash in authors_df\n",
    "domain_subset_df = domain_df[domain_df.domain_cleaned_hash.isin(ac_df.domain_cleaned_hash.unique())]\\\n",
    "                                        [['domain', 'domain_cleaned_hash']]\n",
    "domain_subset_df = domain_subset_df[domain_subset_df.domain.notnull()&domain_subset_df.domain_cleaned_hash.notnull()]\n",
    "\n",
    "domain_subset_all_df = domain_subset_df.rename(columns={'domain_cleaned_hash':'domain_hash'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a6ead",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attempt direct join by hash\n",
    "derived_authors_df = pd.merge(ac_df, domain_subset_all_df\\\n",
    "                              ,how='left', left_on='domain_cleaned_hash', right_on='domain_hash')\\\n",
    "                              .drop('domain_hash', axis=1)\\\n",
    "                              .rename(columns={'domain':'domain_by_citation'})\n",
    "\n",
    "# display\n",
    "derived_authors_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf399f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank the nanoHUB profile institutions that cannot be directly matched by occurance\n",
    "\n",
    "derived_authors_subset_df = derived_authors_df[(derived_authors_df.domain_cleaned_hash.notnull() \\\n",
    "                                                                & derived_authors_df.domain_by_citation.isna())]\n",
    "\n",
    "most_common_sets = derived_authors_subset_df.domain_cleaned_set.value_counts()\n",
    "\n",
    "# display\n",
    "most_common_sets.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9c5aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attempt to reduce domain_df size to speedup Jaccard calculation\n",
    "from itertools import chain\n",
    "\n",
    "all_word_set = set(chain.from_iterable(derived_authors_subset_df.domain_cleaned_set.values))\n",
    "\n",
    "# select the domain_df entry with words from all_word_set\n",
    "domain_subset_df = domain_df[domain_df.domain_cleaned_set.notnull()]\n",
    "domain_subset_df = domain_subset_df[domain_subset_df.domain_cleaned_set\\\n",
    "                             .apply(lambda x: True if len(x.intersection(all_word_set)) > 0 else False)]\n",
    "\n",
    "domain_subset_df = domain_subset_df[['domain_cleaned_set', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe16827",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time consuming part: calculating Jaccard similarity score\n",
    "def get_jaccard_score(a,b):\n",
    "    \n",
    "    if (not a) & (not b):\n",
    "        return 0\n",
    "    \n",
    "    score = len(a.intersection(b))/len(a.union(b))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "for this_set in most_common_sets.index:\n",
    "    # calculate the Jaccard similarity\n",
    "    max_index = domain_subset_df.domain_cleaned_set.apply(lambda x: get_jaccard_score(x, this_set)).idxmax()\n",
    "\n",
    "    derived_authors_df.loc[derived_authors_df.domain_cleaned_set == this_set, 'domain_by_citation'] \\\n",
    "                = domain_subset_df.loc[max_index, 'domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e950b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display\n",
    "derived_authors_df.sample(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a2826",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Obtain Salesforce IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6f384",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create DB2 to Salesforce API object\n",
    "db_s = salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560f65e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query the Salesforce IDs for contacts and citations. when updating junction objects, these IDs must be used\n",
    "\n",
    "# get Salesforce ID for contacts\n",
    "sf_userID_df = db_s.query_data('SELECT Id, nanoHUB_user_ID__c FROM Contact where nanoHUB_user_ID__c != NULL')\n",
    "\n",
    "sf_userID_df['nanoHUB_user_ID__c'] = sf_userID_df['nanoHUB_user_ID__c'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0407037",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get Salesforce ID for citations\n",
    "sf_citationID_df = db_s.query_data('SELECT Id, Record_ID__c FROM nanoHUB_citations__c')\n",
    "\n",
    "sf_citationID_df['Record_ID__c'] = sf_citationID_df['Record_ID__c'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bfb6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get Salesforce ID for organizations\n",
    "sf_orgID_df = db_s.query_data('SELECT Id, Domain__c FROM organization__c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2808c58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Match data with Salesforce format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeba9bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid citation - nanohub user links\n",
    "ac_tolink_df = derived_authors_df[derived_authors_df.nanohub_user_id != 0]\n",
    "\n",
    "display(ac_tolink_df.head(2))\n",
    "display(sf_citationID_df.head(2))\n",
    "display(sf_userID_df.head(2))\n",
    "display(sf_orgID_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39ad52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge SF citation and contact IDs into user-citation DF\n",
    "ac_tolink_df = pd.merge(ac_tolink_df, sf_citationID_df, how='inner', left_on='citation_ID', right_on='Record_ID__c')\\\n",
    "                           .rename(columns={'Id':'SF_ID_citation'})\n",
    "                                            \n",
    "ac_tolink_df = pd.merge(ac_tolink_df, sf_userID_df, how='inner', left_on='nanohub_user_id', right_on='nanoHUB_user_ID__c')\\\n",
    "                           .rename(columns={'Id':'SF_ID_contact'})\n",
    "\n",
    "ac_tolink_df = pd.merge(ac_tolink_df, sf_orgID_df, how='left', left_on='domain_by_citation', right_on='Domain__c')\\\n",
    "                           .rename(columns={'Id':'SF_ID_organization'})\n",
    "\n",
    "# display\n",
    "ac_tolink_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d4d88",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new column for object name\n",
    "ac_tolink_df['Name'] = ac_tolink_df.apply(lambda x: '%d_%d'%(x.nanoHUB_user_ID__c, x.Record_ID__c), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a733d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sf = pd.DataFrame()\n",
    "\n",
    "# Make sure NaN and NaT values are taken care of here\n",
    "df_sf['Name']         = ac_tolink_df['Name']\n",
    "df_sf['Contact__c'] = ac_tolink_df['SF_ID_contact']\n",
    "df_sf['Citation__c'] = ac_tolink_df['SF_ID_citation']\n",
    "\n",
    "df_sf['gscholar_id__c'] = ac_tolink_df['gscholar_id'].fillna('')\n",
    "df_sf['ORCID__c'] = ac_tolink_df['orcid'].fillna('')\n",
    "df_sf['Organization__c'] = ac_tolink_df['SF_ID_organization']\n",
    "df_sf['Organization_nanohub__c'] = ac_tolink_df['organization'].fillna('')\n",
    "df_sf['research_id__c'] = ac_tolink_df['research_id'].fillna('')\n",
    "\n",
    "sf_original_fields = df_sf.columns\n",
    "\n",
    "# display\n",
    "df_sf.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16486f8e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## To Salesforce Sales Cloud CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c49a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create DB2 to Salesforce API object\n",
    "db_s = salesforce\n",
    "\n",
    "# specify Salesforce object ID and external ID\n",
    "db_s.object_id = 'contact_citation_asso__c'\n",
    "db_s.external_id = 'Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1732a29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send data to Salesforce\n",
    "db_s.send_data(df_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab247a31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check status\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(db_s.check_bulk_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be67642",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check status\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(db_s.check_bulk_failed_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb27b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e064d66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "papermill": {
   "duration": 233.835288,
   "end_time": "2021-08-26T03:57:55.734335",
   "environment_variables": {},
   "exception": true,
   "input_path": "nanoHUB/pipeline/salesforce/task_citations_map_contacts.ipynb",
   "output_path": "./.output/task_citations_map_contacts.ipynb",
   "parameters": {},
   "start_time": "2021-08-26T03:54:01.899047",
   "version": "2.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}